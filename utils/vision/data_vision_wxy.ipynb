{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据可视化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px\n",
    "import plotly as py\n",
    "import plotly.io as pio\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shapes(starts, _min, _max, type=None, xref=None, yref=None):\n",
    "    if type == 'service':\n",
    "        color = 'red'\n",
    "    elif type=='pod':\n",
    "        color = 'blue'\n",
    "    elif type == 'node':\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "        \n",
    "    if _min==_max:\n",
    "        _min=0\n",
    "        _max=1\n",
    "    \n",
    "    shapes = []\n",
    "\n",
    "    for r in starts:\n",
    "        w = timedelta(minutes=10)\n",
    "        x0 = r\n",
    "        x1 = r + w\n",
    "        shape = {\n",
    "            'type': 'rect',\n",
    "            'x0': x0,\n",
    "            'y0': _min,\n",
    "            'x1': x1,\n",
    "            'y1': _max,\n",
    "            'fillcolor': color,\n",
    "            'opacity': 0.3,\n",
    "            'line': {\n",
    "                'width': 0,\n",
    "            },\n",
    "        }\n",
    "        if xref is not None:\n",
    "            shape['xref'] = xref\n",
    "            shape['yref'] = yref\n",
    "\n",
    "        shapes.append(shape)\n",
    "\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data1 = pd.read_csv(\n",
    "    '../../data/training_data_with_faults/groundtruth/groundtruth-k8s-1-2022-03-20.csv')\n",
    "label_data2 = pd.read_csv(\n",
    "    '../../data/training_data_with_faults/groundtruth/groundtruth-k8s-1-2022-03-21.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.concat(\n",
    "    [label_data1, label_data2])\n",
    "label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data.sort_values(by=['level', 'cmdb_id','timestamp'], inplace=True)\n",
    "label_data.reset_index(drop=True, inplace=True)\n",
    "label_data['datetime'] = pd.to_datetime(\n",
    "    label_data['timestamp'], unit='s')\n",
    "\n",
    "label_data.to_csv('../data/label/label1.csv', index=False)\n",
    "label_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 业务指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### service级别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../data/label/label1.csv')\n",
    "label_data['datetime'] = pd.to_datetime(label_data['datetime'])\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_metric_data1 = pd.read_csv(\n",
    "#     '../data/training_data_normal/cloudbed-1/metric/service/metric_service.csv')\n",
    "# service_metric_data2 = pd.read_csv(\n",
    "#     '../data/training_data_normal/cloudbed-2/metric/service/metric_service.csv')\n",
    "# service_metric_data3 = pd.read_csv(\n",
    "#     '../data/training_data_normal/cloudbed-3/metric/service/metric_service.csv')\n",
    "\n",
    "\n",
    "service_metric_data1 = pd.read_csv(\n",
    "    '../data/training_data_with_faults/tar/2022-03-20-cloudbed1/metric/service/metric_service.csv')\n",
    "service_metric_data2 = pd.read_csv(\n",
    "    '../data/training_data_with_faults/tar/2022-03-21-cloudbed1/metric/service/metric_service.csv')\n",
    "# service_metric_data3 = pd.read_csv(\n",
    "#     '../data/training_data_with_faults/tar/2022-03-20-cloudbed2/metric/service/metric_service.csv')\n",
    "# service_metric_data4 = pd.read_csv(\n",
    "#     '../data/training_data_with_faults/tar/2022-03-21-cloudbed2/metric/service/metric_service.csv')\n",
    "# service_metric_data5 = pd.read_csv(\n",
    "#     '../data/training_data_with_faults/tar/2022-03-20-cloudbed3/metric/service/metric_service.csv')\n",
    "# service_metric_data6 = pd.read_csv(\n",
    "#     '../data/training_data_with_faults/tar/2022-03-21-cloudbed3/metric/service/metric_service.csv')\n",
    "# service_metric_data7 = pd.read_csv(\n",
    "#     '../data/training_data_with_faults/tar/2022-03-24-cloudbed3/metric/service/metric_service.csv')\n",
    "\n",
    "# service_metric_data=pd.concat([service_metric_data1,service_metric_data2,service_metric_data3])\n",
    "# service_metric_data = pd.concat(\n",
    "#     [service_metric_data1, service_metric_data2, service_metric_data3, service_metric_data4, service_metric_data5,service_metric_data6,service_metric_data7])\n",
    "service_metric_data = pd.concat(\n",
    "    [service_metric_data1, service_metric_data2])\n",
    "# service_metric_data=service_metric_data1\n",
    "service_metric_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_service_metric_data = list(service_metric_data.groupby('service'))\n",
    "for (service_name, service_data) in tqdm(processed_service_metric_data):\n",
    "    service_data.sort_values(by='timestamp', inplace=True)\n",
    "    service_data.reset_index(drop=True, inplace=True)\n",
    "    service_data['datetime'] = pd.to_datetime(\n",
    "        service_data['timestamp'], unit='s')\n",
    "\n",
    "    # processed_data_path = f'../data/training_data_normal/processed_service_metric_data/'\n",
    "    processed_data_path = f'../data/training_data_with_faults/tar/processed_service_metric_data/'\n",
    "    os.makedirs(processed_data_path, exist_ok=True)\n",
    "    service_data.to_csv(processed_data_path+service_name +\n",
    "                        '_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_service_metric_data = list(service_metric_data.groupby('service'))\n",
    "for (service_name,service_data) in tqdm(processed_service_metric_data):\n",
    "    service_data.sort_values(by='timestamp', inplace=True)\n",
    "    service_data.reset_index(drop=True, inplace=True)\n",
    "    service_data['datetime'] = pd.to_datetime(\n",
    "        service_data['timestamp'], unit='s')\n",
    "    \n",
    "    visualization_path = f'../result/visualization/with_faults/service/'\n",
    "    os.makedirs(visualization_path, exist_ok=True)\n",
    "    \n",
    "    label_data_service= label_data[(label_data['level'] == 'service') & (\n",
    "        label_data['cmdb_id'] == service_name.split('-')[0])]\n",
    "    label_data_pod=label_data[(label_data['level'] == 'pod') & (\n",
    "        label_data['cmdb_id'].str.contains(service_name.split('-')[0]))]\n",
    "    \n",
    "    fig = make_subplots(rows=4, cols=1, shared_xaxes=True)\n",
    "    shapes = []\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=service_data['datetime'], y=service_data['rr'], name='rr',\n",
    "                                marker=dict(color='rgb(255, 127, 14, 1)', size=1), mode='markers',legendgroup=\"group1\",\n",
    "                                legendgrouptitle_text=\"Data Type\"), row=1, col=1)\n",
    "    shapes += create_shapes(label_data_service['datetime'], _min=0,\n",
    "                            _max=service_data['rr'].max(), type='service', xref='x1', yref='y1')\n",
    "    shapes += create_shapes(label_data_pod['datetime'], _min=0,\n",
    "                            _max=service_data['rr'].max(), type='pod', xref='x1', yref='y1')\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=service_data['datetime'], y=service_data['sr'], name='sr',\n",
    "                                marker=dict(color='rgb(0, 204, 150, 1)', size=1), mode='markers', legendgroup=\"group1\",\n",
    "                                legendgrouptitle_text=\"Data Type\"), row=2, col=1)\n",
    "    shapes += create_shapes(label_data_service['datetime'], _min=0,\n",
    "                            _max=service_data['sr'].max(), type='service', xref='x2', yref='y2')\n",
    "    shapes += create_shapes(label_data_pod['datetime'], _min=0,\n",
    "                            _max=service_data['sr'].max(), type='pod', xref='x2', yref='y2')\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=service_data['datetime'], y=service_data['mrt'], name='mrt',\n",
    "                                line=dict(color='rgb(31, 119, 180, 1)', width=1), mode='lines', legendgroup=\"group1\",\n",
    "                                legendgrouptitle_text=\"Data Type\"), row=3, col=1)\n",
    "    shapes += create_shapes(label_data_service['datetime'], _min=0,\n",
    "                            _max=service_data['mrt'].max(), type='service', xref='x3', yref='y3')\n",
    "    shapes += create_shapes(label_data_pod['datetime'], _min=0,\n",
    "                            _max=service_data['mrt'].max(), type='pod', xref='x3', yref='y3')\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=service_data['datetime'], y=service_data['count'], name='count',\n",
    "                                line=dict(color='rgb(0, 0, 0, 1)', width=1), mode='lines', legendgroup=\"group1\",\n",
    "                                legendgrouptitle_text=\"Data Type\"), row=4, col=1)\n",
    "    shapes += create_shapes(label_data_service['datetime'], _min=0,\n",
    "                            _max=service_data['count'].max(), type='service', xref='x4', yref='y4')\n",
    "    shapes += create_shapes(label_data_pod['datetime'], _min=0,\n",
    "                            _max=service_data['count'].max(), type='pod', xref='x4', yref='y4')\n",
    "    \n",
    "    fig.append_trace(go.Scatter(x=[service_data['datetime'][0]], y=[service_data['rr'][0]], legendgroup='group2', legendgrouptitle_text='Label Type',\n",
    "                                name='service label', mode=\"lines\", line=dict(color='red')), row=1, col=1)\n",
    "    fig.append_trace(go.Scatter(x=[service_data['datetime'][0]], y=[service_data['rr'][0]], legendgroup='group2', legendgrouptitle_text='Label Type',\n",
    "                                name='pod label',mode=\"lines\",line=dict(color='blue')), row=1, col=1)\n",
    "    \n",
    "    fig.update_layout(title_text=service_name, shapes=shapes)\n",
    "    pio.write_html(fig, file=visualization_path+service_name+'.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### node级别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../data/label/label1.csv')\n",
    "label_data['datetime'] = pd.to_datetime(label_data['datetime'])\n",
    "cmdb_id = label_data[label_data['level'] =='node']['cmdb_id'].drop_duplicates().tolist()\n",
    "cmdb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_metric_data1=pd.read_csv('../data/training_data_with_faults/tar/2022-03-20-cloudbed1/metric/node/kpi_cloudbed1_metric_0320.csv')\n",
    "node_metric_data2=pd.read_csv('../data/training_data_with_faults/tar/2022-03-21-cloudbed1/metric/node/kpi_cloudbed1_metric_0321.csv')\n",
    "node_metric_data=pd.concat([node_metric_data1,node_metric_data2])\n",
    "\n",
    "# node_metric_data = pd.read_csv(\n",
    "#     '../data/training_data_normal/cloudbed-1/metric/node/kpi_cloudbed1_metric_0319.csv')\n",
    "\n",
    "node_metric_data['datetime'] = pd.to_datetime(\n",
    "    node_metric_data['timestamp'], unit='s')\n",
    "\n",
    "node_metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_node_metric_data=list(node_metric_data.groupby('kpi_name'))\n",
    "\n",
    "for kpi_name,kpi_data in tqdm(processed_node_metric_data):\n",
    "    kpi_data.sort_values(by=['cmdb_id', 'timestamp'], inplace=True)\n",
    "    kpi_data.reset_index(drop=True, inplace=True)\n",
    "    # processed_data_path = f'../data/training_data_normal/processed_node_metric_data/'\n",
    "    processed_data_path = f'../data/training_data_with_faults/tar/processed_node_metric_data/'\n",
    "    os.makedirs(processed_data_path, exist_ok=True)\n",
    "    kpi_data.to_csv(processed_data_path+kpi_name +'_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['cpu&load','mem','disk&fs','io','net&can_connect&tcp&udp','swap','os&user','process']\n",
    "colors = ['blue', 'green', 'orange', 'purple', 'brown','pink', 'gray', 'olive', 'cyan', 'magenta']\n",
    "\n",
    "for cat in tqdm(categories):\n",
    "    node_data=pd.DataFrame()\n",
    "    cat_list=cat.split('&')\n",
    "    for c in cat_list:\n",
    "        node_metric_data['kpi_cat'] = node_metric_data['kpi_name'].apply(\n",
    "            lambda x: x.split('.')[1])\n",
    "        node_data = pd.concat(\n",
    "            [node_data, node_metric_data[node_metric_data['kpi_cat'] == c]])\n",
    "        \n",
    "    kpi_num = len(node_data['kpi_name'].drop_duplicates())\n",
    "    cmdb_num = len(node_data['cmdb_id'].drop_duplicates())\n",
    "    \n",
    "    processed_node_data=list(node_data.groupby('cmdb_id'))\n",
    "    \n",
    "    visualization_path = f'../result/visualization/with_faults/node/'+cat+'/'\n",
    "    os.makedirs(visualization_path, exist_ok=True)\n",
    "    \n",
    "    for node_id, kpi_data in processed_node_data:\n",
    "        fig = make_subplots(rows=kpi_num, cols=1, shared_xaxes=True,\n",
    "                            subplot_titles=kpi_data['kpi_name'].drop_duplicates().sort_values().tolist())\n",
    "        shapes = []\n",
    "        \n",
    "        kpi_data.sort_values(by='timestamp', inplace=True)\n",
    "        kpi_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        label_data_i = label_data[(label_data['level'] == 'node') & (\n",
    "            label_data['cmdb_id'] == node_id)]\n",
    "        \n",
    "        kpi_data = list(kpi_data.groupby(['kpi_name']))\n",
    "        \n",
    "        for i,(kpi,data) in enumerate(kpi_data):\n",
    "            data.sort_values(by='timestamp', inplace=True)\n",
    "            data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            shapes += create_shapes(\n",
    "                label_data_i['datetime'], _min=0, _max=data['value'].max(), xref='x'+str(i+1), yref='y'+str(i+1))\n",
    "            fig.append_trace(go.Scatter(x=data['datetime'], y=data['value'], name=kpi,\n",
    "                                        line=dict(color=colors[i % 10], width=1.5), mode='lines'), row=i+1, col=1)\n",
    "\n",
    "        fig.update_layout(title_text=node_id, shapes=shapes)\n",
    "        pio.write_html(fig, file=visualization_path+node_id+'.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### container级别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../data/label/label1.csv')\n",
    "label_data['datetime'] = pd.to_datetime(label_data['datetime'])\n",
    "\n",
    "cmdb_id_service = label_data[label_data['level'] ==\n",
    "                     'service']['cmdb_id'].drop_duplicates().tolist()\n",
    "\n",
    "cmdb_id_raw = label_data[label_data['level'] ==\n",
    "                     'service']['cmdb_id'].drop_duplicates().tolist()\n",
    "cmdb_id_pod = []\n",
    "pre = ['', '2']\n",
    "for id in cmdb_id_raw:\n",
    "    for p in pre:\n",
    "        for i in range(3):\n",
    "            cmdb_id_pod.append(id+f'{p}-{i}')\n",
    "\n",
    "cmdb_id_node = label_data[label_data['level'] ==\n",
    "                     'node']['cmdb_id'].drop_duplicates().tolist()\n",
    "\n",
    "# 查看后发现container的network类的指标多了这一类的cmdb_id，但是再label中没有此类cmdb_id\n",
    "cmdb_id_pod.append('redis-cart')\n",
    "cmdb_id_pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path1 = f'../data/training_data_with_faults/tar/2022-03-20-cloudbed1/metric/container/'\n",
    "dir_path2 = f'../data/training_data_with_faults/tar/2022-03-21-cloudbed1/metric/container/'\n",
    "dir_content = os.listdir(dir_path1)\n",
    "categories = ['cpu', 'memory', 'fs', 'network',\n",
    "              'spec', 'threads&processes&ulimits']\n",
    "colors = ['blue', 'green', 'orange', 'purple', 'brown',\n",
    "          'pink', 'gray', 'olive', 'cyan', 'magenta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in tqdm(categories):\n",
    "    file_name_set = [i for i in dir_content if i.split('.')[0].split('_')[2] in cat]\n",
    "    container_data=pd.DataFrame()\n",
    "    for filename in file_name_set:\n",
    "        file_path1=dir_path1+filename\n",
    "        file_path2=dir_path2+filename\n",
    "        container_data1=pd.read_csv(file_path1)\n",
    "        container_data2=pd.read_csv(file_path2)\n",
    "        container_data = pd.concat(\n",
    "            [container_data,container_data1, container_data2])\n",
    "    \n",
    "    container_data['datetime'] = pd.to_datetime(container_data['timestamp'], unit='s')\n",
    "    container_data['cmdb_id_pod'] = container_data['cmdb_id']\n",
    "    container_data['cmdb_id_service'] = container_data['cmdb_id']\n",
    "    container_data['cmdb_id_node'] = container_data['cmdb_id']\n",
    "    \n",
    "    for i in cmdb_id_pod:\n",
    "        container_data['cmdb_id_pod'] = container_data['cmdb_id_pod'].apply(\n",
    "            lambda x: i if i in x else x)\n",
    "    \n",
    "    for i in cmdb_id_service:\n",
    "        container_data['cmdb_id_service'] = container_data['cmdb_id_service'].apply(\n",
    "            lambda x: i if i in x else x)\n",
    "        \n",
    "    # for i in cmdb_id_node:\n",
    "    #     container_data['cmdb_id_node'] = container_data['cmdb_id_node'].apply(\n",
    "    #         lambda x: i if i in x else x)\n",
    "        \n",
    "    processed_container_data = list(container_data.groupby(['cmdb_id_pod']))\n",
    "    \n",
    "    for id, kpi_data in processed_container_data:\n",
    "        kpi_data.sort_values(by='timestamp', inplace=True)\n",
    "        kpi_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        cmdb_num = len(kpi_data['cmdb_id'].drop_duplicates())\n",
    "        kpi_num = len(kpi_data['kpi_name'].drop_duplicates())\n",
    "        \n",
    "        service_ids=kpi_data['cmdb_id_service'].drop_duplicates().tolist()\n",
    "        # node_ids=kpi_data['cmdb_id_node'].drop_duplicates().tolist()\n",
    "        \n",
    "        service_id = service_ids[0] if len(service_ids)==1 else ''\n",
    "        # node_id = node_ids[0] if len(service_ids) == 1 else ''\n",
    "        \n",
    "        label_data_pod = label_data[(label_data['level'] == 'pod') & (\n",
    "            label_data['cmdb_id'] == id)]\n",
    "        label_data_service = label_data[(label_data['level'] == 'service') & (\n",
    "            label_data['cmdb_id'] == service_id)]\n",
    "        # label_data_node = label_data[(label_data['level'] == 'node') & (\n",
    "        #     label_data['cmdb_id'] == node_id)]\n",
    "\n",
    "        visualization_path = f'../result/visualization/with_faults/container/'+cat+'/'\n",
    "        os.makedirs(visualization_path, exist_ok=True)\n",
    "\n",
    "        fig = make_subplots(rows=kpi_num, cols=1, shared_xaxes=True,\n",
    "                            subplot_titles=kpi_data['kpi_name'].drop_duplicates().sort_values().tolist())\n",
    "        \n",
    "        shapes = []\n",
    "\n",
    "        kpi_data_temp = list(kpi_data.groupby(['kpi_name']))\n",
    "        kpi_data = list(kpi_data.groupby(['kpi_name', 'cmdb_id']))\n",
    "\n",
    "        for i in range(kpi_num):\n",
    "            shapes += create_shapes(\n",
    "                label_data_service['datetime'], _min=0, _max=kpi_data_temp[i][1]['value'].max(),type='service', xref='x'+str(i+1), yref='y'+str(i+1))\n",
    "            shapes += create_shapes(\n",
    "                label_data_pod['datetime'], _min=0, _max=kpi_data_temp[i][1]['value'].max(), type='pod', xref='x'+str(i+1), yref='y'+str(i+1))\n",
    "            # shapes += create_shapes(\n",
    "            #     label_data_node['datetime'], _min=0, _max=kpi_data_temp[i][1]['value'].max(), type='node', xref='x'+str(i+1), yref='y'+str(i+1))\n",
    "            for j in range(cmdb_num):\n",
    "                ((kpi, cmdb), data) = kpi_data[i*cmdb_num+j]\n",
    "                data.sort_values(by='timestamp', inplace=True)\n",
    "                data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                fig.append_trace(go.Scatter(x=data['datetime'], y=data['value'], name=cmdb,\n",
    "                                            line=dict(color=colors[j % 10], width=1.5), mode='lines', legendgroup=\"group1\",\n",
    "                                            legendgrouptitle_text=\"Data Type\"), row = i+1, col = 1)\n",
    "\n",
    "        fig.append_trace(go.Scatter(x=[data['datetime'][0]], y=[data['value'][0]], legendgroup='group2', legendgrouptitle_text='Label Type',\n",
    "                                    name='service label', mode=\"lines\", line=dict(color='red')), row=1, col=1)\n",
    "        fig.append_trace(go.Scatter(x=[data['datetime'][0]], y=[data['value'][0]], legendgroup='group2', legendgrouptitle_text='Label Type',\n",
    "                                name='pod label', mode=\"lines\", line=dict(color='blue')), row=1, col=1)\n",
    "        # fig.append_trace(go.Scatter(x=[data['datetime'][0]], y=[data['value'][0]], legendgroup='group2', legendgrouptitle_text='Label Type',\n",
    "        #                             name='node label', mode=\"lines\", line=dict(color='green')), row=1, col=1)\n",
    "        \n",
    "        fig.update_layout(title_text=id, shapes=shapes)\n",
    "        pio.write_html(fig, file=visualization_path+id+'.html')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cd3cb958197236635b33eb3a41ee2e4d17ce24cee0fc13a23e30642bde7914e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aiops2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
